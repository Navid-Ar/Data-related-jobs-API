{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\Navid\\Documents\\ds_salary_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('eda_data_modified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.loc[df.Industry != '-1']\n",
    "df = df.loc[df['Type of ownership'] != 'Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df.Size != '-1') & (df.Size != 'Unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'index', 'Job Title', 'Job Description', 'Rating',\n",
       "       'Company Name', 'Location', 'Size', 'Founded', 'Type of ownership',\n",
       "       'Industry', 'Sector', 'Revenue', 'Competitors', 'per_hour',\n",
       "       'avg_salary', 'FAANG', 'state', 'desc_length', 'junior', 'seniority',\n",
       "       'title', 'intern', 'python', 'ML', 'big_data', 'deep_learning',\n",
       "       'cloud_computing', 'graduate', 'undergrad', 'exp_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df[['avg_salary' ,'Size','Type of ownership', 'Rating', \n",
    "               'Sector', 'Revenue','per_hour', 'seniority', \n",
    "               'state', 'cloud_computing', 'title', 'big_data', \n",
    "       'deep_learning', 'graduate', 'undergrad','exp_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[df_final.Rating != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing skewness\n",
    "# from scipy import stats\n",
    "# df['avg_salary'] ,fitted_lambda1 = stats.boxcox(df['avg_salary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_col =['Size','Type of ownership',  \n",
    "               'Sector', 'Revenue', 'state', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Size': {'1 to 50 Employees': 0, '10000+ Employees': 1, '1001 to 5000 Employees': 2, '201 to 500 Employees': 3, '5001 to 10000 Employees': 4, '501 to 1000 Employees': 5, '51 to 200 Employees': 6}, 'Type of ownership': {'College / University': 0, 'Company - Private': 1, 'Company - Public': 2, 'Contract': 3, 'Government': 4, 'Hospital': 5, 'Nonprofit Organization': 6, 'Other Organization': 7, 'Private Practice / Firm': 8, 'School / School District': 9, 'Subsidiary or Business Segment': 10}, 'Sector': {'-1': 0, 'Accounting & Legal': 1, 'Aerospace & Defense': 2, 'Agriculture & Forestry': 3, 'Arts, Entertainment & Recreation': 4, 'Biotech & Pharmaceuticals': 5, 'Business Services': 6, 'Construction, Repair & Maintenance': 7, 'Consumer Services': 8, 'Education': 9, 'Finance': 10, 'Government': 11, 'Health Care': 12, 'Information Technology': 13, 'Insurance': 14, 'Manufacturing': 15, 'Media': 16, 'Mining & Metals': 17, 'Non-Profit': 18, 'Oil, Gas, Energy & Utilities': 19, 'Real Estate': 20, 'Restaurants, Bars & Food Services': 21, 'Retail': 22, 'Telecommunications': 23, 'Transportation & Logistics': 24, 'Travel & Tourism': 25}, 'Revenue': {'$1 to $2 billion (USD)': 0, '$1 to $5 million (USD)': 1, '$10 to $25 million (USD)': 2, '$10+ billion (USD)': 3, '$100 to $500 million (USD)': 4, '$2 to $5 billion (USD)': 5, '$25 to $50 million (USD)': 6, '$5 to $10 billion (USD)': 7, '$5 to $10 million (USD)': 8, '$50 to $100 million (USD)': 9, '$500 million to $1 billion (USD)': 10, 'Less than $1 million (USD)': 11, 'Unknown / Non-Applicable': 12}, 'state': {'AK': 0, 'AL': 1, 'AR': 2, 'AZ': 3, 'Arapahoe': 4, 'CA': 5, 'CO': 6, 'CT': 7, 'DC': 8, 'DE': 9, 'FL': 10, 'GA': 11, 'IA': 12, 'ID': 13, 'IL': 14, 'IN': 15, 'KS': 16, 'KY': 17, 'LA': 18, 'MA': 19, 'MD': 20, 'ME': 21, 'MI': 22, 'MN': 23, 'MO': 24, 'MS': 25, 'NC': 26, 'NE': 27, 'NH': 28, 'NJ': 29, 'NM': 30, 'NV': 31, 'NY': 32, 'OH': 33, 'OK': 34, 'OR': 35, 'PA': 36, 'PR': 37, 'RI': 38, 'SC': 39, 'TN': 40, 'TX': 41, 'UT': 42, 'VA': 43, 'VT': 44, 'WA': 45, 'WI': 46, 'WV': 47, 'WY': 48}, 'title': {'data analyst': 0, 'data architect': 1, 'data engineer': 2, 'data scientist': 3, 'machine learning engineer': 4}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "mapping_dict={}\n",
    "for col in category_col:\n",
    "    le = LabelEncoder()\n",
    "    df_final[col] = le.fit_transform(df_final[col])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    mapping_dict[col]=le_name_mapping\n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dummy.drop('Industry_other_industries',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# df[['avg_salary', 'Rating', 'exp_year']] = scaler.fit_transform(df[['avg_salary', 'Rating', 'exp_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = df_final.drop('avg_salary' , axis = 1)\n",
    "y = df_final['avg_salary'].values\n",
    "X_train , X_test , y_train , y_test = train_test_split(x , y , test_size = 0.2 , random_state = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets start with random grid search to narrow down the ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, \n",
    "                               cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring = 'neg_mean_absolute_error')\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-12.485552812373891 RandomForestRegressor(bootstrap=False, max_features='sqrt', n_estimators=400)\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_score_,rf_random.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': range(570,650,10)\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "grid = GridSearchCV(RandomForestRegressor(n_jobs=-1 ,random_state = 42, bootstrap = False, max_features =  'sqrt'), \n",
    "                    param_grid = param_grid, scoring = 'neg_mean_absolute_error',  cv =8).fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.51880081695691 RandomForestRegressor(bootstrap=False, max_features='sqrt', n_estimators=630,\n",
      "                      n_jobs=-1, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_,grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.557259655377306"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(grid.best_estimator_, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
